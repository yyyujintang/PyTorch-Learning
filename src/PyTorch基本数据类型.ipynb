{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch基本数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "a.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(a,torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 标量,dimension为0，eg计算误差loss时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.tensor(2.2)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimension为1,eg,Bias,偏置;神经网络线性输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1000, 2.2000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.1,2.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(1) #随机初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =np.ones(2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimension：eg二维行和列;size/shape具体形状[2,2];tensor:具体数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimesion为2 eg,linear input batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3345,  2.1185,  0.7922],\n",
       "        [ 1.3190, -1.3794, -0.4058]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.randn(2,3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape[1] #对shape进行索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimension为3 eg, RNN input batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9304, 0.7909, 0.5167],\n",
       "         [0.5552, 0.9735, 0.3432]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=torch.rand(1,2,3)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9304, 0.7909, 0.5167],\n",
       "        [0.5552, 0.9735, 0.3432]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension为4，适合图片eg.CNN [b,c,h,w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6811, 0.3725, 0.9168,  ..., 0.5270, 0.1414, 0.9535],\n",
       "          [0.4592, 0.2653, 0.5756,  ..., 0.0771, 0.9350, 0.8320],\n",
       "          [0.7568, 0.2955, 0.3753,  ..., 0.9046, 0.6161, 0.5191],\n",
       "          ...,\n",
       "          [0.9835, 0.2756, 0.4478,  ..., 0.9845, 0.6428, 0.4608],\n",
       "          [0.7401, 0.9897, 0.5383,  ..., 0.1886, 0.2317, 0.8230],\n",
       "          [0.0569, 0.5405, 0.3870,  ..., 0.5507, 0.6816, 0.9340]],\n",
       "\n",
       "         [[0.9420, 0.9554, 0.3571,  ..., 0.2346, 0.3221, 0.7390],\n",
       "          [0.8999, 0.5828, 0.5915,  ..., 0.5964, 0.5815, 0.1366],\n",
       "          [0.6351, 0.8604, 0.6905,  ..., 0.8597, 0.5351, 0.3339],\n",
       "          ...,\n",
       "          [0.2014, 0.7845, 0.0470,  ..., 0.7053, 0.9324, 0.1873],\n",
       "          [0.2958, 0.0393, 0.1077,  ..., 0.3186, 0.9842, 0.3359],\n",
       "          [0.0048, 0.7742, 0.6835,  ..., 0.3363, 0.3447, 0.0031]],\n",
       "\n",
       "         [[0.8524, 0.1225, 0.6456,  ..., 0.7566, 0.3619, 0.6459],\n",
       "          [0.6676, 0.1592, 0.8735,  ..., 0.2162, 0.9637, 0.7763],\n",
       "          [0.3543, 0.6444, 0.0888,  ..., 0.4019, 0.0132, 0.3426],\n",
       "          ...,\n",
       "          [0.2650, 0.5434, 0.0315,  ..., 0.5174, 0.9892, 0.3058],\n",
       "          [0.2990, 0.8411, 0.9096,  ..., 0.1638, 0.7600, 0.0045],\n",
       "          [0.9550, 0.2624, 0.6483,  ..., 0.1575, 0.6289, 0.1352]]],\n",
       "\n",
       "\n",
       "        [[[0.7475, 0.3774, 0.0241,  ..., 0.4129, 0.3416, 0.0096],\n",
       "          [0.0753, 0.2717, 0.2425,  ..., 0.7446, 0.8218, 0.4845],\n",
       "          [0.5110, 0.8993, 0.7807,  ..., 0.2709, 0.6846, 0.8289],\n",
       "          ...,\n",
       "          [0.1929, 0.0469, 0.0696,  ..., 0.8986, 0.2281, 0.6043],\n",
       "          [0.5331, 0.0029, 0.5795,  ..., 0.2461, 0.7002, 0.4757],\n",
       "          [0.4089, 0.1278, 0.7471,  ..., 0.1682, 0.3878, 0.6805]],\n",
       "\n",
       "         [[0.8396, 0.8703, 0.4800,  ..., 0.8808, 0.8461, 0.6344],\n",
       "          [0.8537, 0.1142, 0.2537,  ..., 0.4624, 0.9791, 0.9573],\n",
       "          [0.8980, 0.0204, 0.9199,  ..., 0.9245, 0.4324, 0.8308],\n",
       "          ...,\n",
       "          [0.2134, 0.7164, 0.7347,  ..., 0.7137, 0.5612, 0.5357],\n",
       "          [0.4269, 0.4833, 0.0965,  ..., 0.7516, 0.2658, 0.0231],\n",
       "          [0.1595, 0.6798, 0.4480,  ..., 0.2476, 0.7907, 0.4163]],\n",
       "\n",
       "         [[0.2007, 0.5397, 0.2872,  ..., 0.0392, 0.7342, 0.9198],\n",
       "          [0.2344, 0.3866, 0.1952,  ..., 0.1519, 0.7303, 0.9016],\n",
       "          [0.8514, 0.2642, 0.4747,  ..., 0.7241, 0.0256, 0.7420],\n",
       "          ...,\n",
       "          [0.7209, 0.2369, 0.4677,  ..., 0.8767, 0.3409, 0.6015],\n",
       "          [0.5960, 0.7832, 0.4465,  ..., 0.1802, 0.6970, 0.9305],\n",
       "          [0.1233, 0.9735, 0.5894,  ..., 0.4114, 0.3033, 0.8658]]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=torch.rand(2,3,28,28)#28*28,图片长宽，3代表通道RGB，2代表2张照片 [batch,channel.height.weighth],适合卷积神经网络\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 28, 28])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4704"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.numel()#number of element 2*3*28*28=4708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.dim()#返回dimension"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
